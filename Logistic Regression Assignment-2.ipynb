{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42857bbb-07f5-474e-b916-d2b800eb13e1",
   "metadata": {},
   "source": [
    "# Logistic  Regression Assignment-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fea1a-3b83-431c-8d4b-69d10f4a2e10",
   "metadata": {},
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e22892-10d3-4363-a17e-7167129b1248",
   "metadata": {},
   "source": [
    "The purpose of grid search cv is to systematically search through a predefined set of hyperparameter and find the  combination that produces the best performence for a given evaluation metric.\n",
    "\n",
    "GridSearchCV automates the process of hyperparameter tuning, make it easy for machine learning model to find the best  model configuration without the need of manual trial and error.  \n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933cd9ec-80cf-4d69-87a5-aa0ede254aa2",
   "metadata": {},
   "source": [
    "Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
    "one over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d2603-ba44-437f-85c7-d4fac54ab7c1",
   "metadata": {},
   "source": [
    "Grid Search CV:  Grid Search CV exhaustively searches through a specified subset of the hyperparameter space. It evaluates all possible combinations of hyperparameters that you provide in a grid-like fashion.\n",
    "\n",
    "Randomized Search CV: Randomized Search CV randomly selects a subset of hyperparameters from a predefined distribution for a fixed number of iterations.\n",
    "\n",
    "Grid Search cv is like checking every on grocery list one by one.\n",
    "\n",
    "Randomized Search cv is like picking items randomly from a gorcery store.\n",
    "\n",
    "When to Choose One Over the Other:\n",
    "\n",
    "Grid Search CV: Choose Grid Search CV when the hyperparameter space is relatively small, and computational resources allow for exploring all possible combinations. It ensures a thorough search through the hyperparameter space.\n",
    "\n",
    "Randomized Search CV: Choose Randomized Search CV when the hyperparameter space is large and exploring every possible combination is impractical. It's more efficient in such scenarios and can still yield good results by sampling a subset of the space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043a359-bcdf-4ba0-949c-41746b9af629",
   "metadata": {},
   "source": [
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed6adf-fb68-4245-bb51-eeb1302d9eb2",
   "metadata": {},
   "source": [
    "Data leakage in machine learning refers to a  situation where information from outside the training dataset is used to create a model.\n",
    "\n",
    "Data leakage is a problem because it violates the fundamental assumption that the training data and the test (or deployment) data should come from the same distribution. Models trained with leaked data can perform well on the training and validation sets but fail to generalize to new data in real-world scenarios.\n",
    "\n",
    "Training Phase: You train your model using historical stock data, including the stock prices from the day before as a feature.\n",
    "\n",
    "Testing Phase: During testing, when you evaluate your model's performance, the model sees the stock prices from the day before for the test data. This information wasn't available at the time of prediction in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca5f0c-662a-4af5-94f1-cf00b8d62678",
   "metadata": {},
   "source": [
    "Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c6d90-5752-4f2c-aa41-b34106c60675",
   "metadata": {},
   "source": [
    "Here are some strategy to prevent from data leakage:-\n",
    "\n",
    "1) Split Data Properly:\n",
    "\n",
    "2) Feature Engineering:\n",
    "\n",
    "3) Use Time Series Cross-Validation:\n",
    "\n",
    "4) Avoid Data Leakage in Preprocessing: \n",
    "\n",
    "5) Handle Missing Values Carefully: \n",
    "\n",
    "6) Watch for Leakage Indicators:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca683db6-90aa-407e-97ae-d0d7aab6de09",
   "metadata": {},
   "source": [
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9c208-169c-4464-8303-68f52e02922c",
   "metadata": {},
   "source": [
    "\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
    "\n",
    "Here's what each term in a confusion matrix represents:\n",
    "\n",
    "True Positive (TP): The cases in which the model correctly predicted the positive class.\n",
    "\n",
    "True Negative (TN): The cases in which the model correctly predicted the negative class.\n",
    "\n",
    "False Positive (FP): The cases in which the model incorrectly predicted the positive class (Type I error).\n",
    "\n",
    "False Negative (FN): The cases in which the model incorrectly predicted the negative class (Type II error).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba80703-b3d2-4d4a-befe-af3836a788d6",
   "metadata": {},
   "source": [
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058937ab-d070-4d30-83b7-a9248137b16c",
   "metadata": {},
   "source": [
    "1) Precision:\n",
    "\n",
    "Precision measures the accuracy of positive predictions made by the model. It answers the question: \"Out of all the instances predicted as positive, how many were actually positive?\" Mathematically, precision is calculated as the ratio of true positives to the sum of true positives and false positives\n",
    "\n",
    "Precision= \n",
    "TP/TP+FP\n",
    "\n",
    "Precision is high when the number of false positives is low, indicating that the model makes fewer incorrect positive predictions.\n",
    "\n",
    "2) Recall (or Sensitivity):\n",
    "\n",
    "Recall measures the ability of the model to correctly identify positive instances. It answers the question: \"Out of all the actual positive instances, how many did the model correctly identify?\" Mathematically, recall is calculated as the ratio of true positives to the sum of true positives and false negatives:\n",
    "\n",
    "\n",
    "Recall= \n",
    "TP/TP+FN\n",
    "â€‹\n",
    " \n",
    "Recall is high when the number of false negatives is low, indicating that the model captures most of the positive instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082a7c9-8aaa-4199-9167-8f4837f1be60",
   "metadata": {},
   "source": [
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fcc96-bb75-4673-80dd-8c0c62436215",
   "metadata": {},
   "source": [
    "True Positive (TP): The cases in which the model correctly predicted the positive class.\n",
    "\n",
    "True Negative (TN): The cases in which the model correctly predicted the negative class.\n",
    "\n",
    "False Positive (FP): The cases in which the model incorrectly predicted the positive class (Type I error).\n",
    "\n",
    "False Negative (FN): The cases in which the model incorrectly predicted the negative class (Type II error).\n",
    "\n",
    ". Analyzing these elements can provide valuable insights:\n",
    "\n",
    "Imbalanced Errors: If you notice a significant difference between the number of false positives and false negatives, it could indicate that your model is biased towards one class. For instance, if you have many false negatives in a medical diagnosis task, it means your model is failing to detect positive cases.\n",
    "\n",
    "Performance on Each Class: Look at how the errors are distributed across different classes. If your model is consistently misclassifying one class more than others, it might indicate a problem with the features or the model's ability to distinguish that class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3736281-6400-45d1-92ce-1f021632bec0",
   "metadata": {},
   "source": [
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd5149-d950-4d1a-8477-298f77df170d",
   "metadata": {},
   "source": [
    "Common metrics derived from a confusion matrix include:\n",
    "\n",
    "1) Accuracy: Measures the overall correctness of predictions.\n",
    "\n",
    "\n",
    "Accuracy= \n",
    "TP+TN/TP+TN+FP+FN\n",
    "\n",
    "\n",
    "2) Precision: Measures the accuracy of positive predictions.\n",
    "\n",
    "\n",
    "Precision= \n",
    "TP/TP+FP\n",
    "\n",
    "3) Recall (Sensitivity): Measures the ability to correctly identify positive instances.\n",
    "\n",
    "\n",
    "Recall= \n",
    "TP/TP+FN\n",
    "\n",
    "4) Specificity: Measures the ability to correctly identify negative instances.\n",
    "\n",
    "\n",
    "Specificity= \n",
    "TN/TN+FP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b3c58-79a7-4cf8-9947-381ddcaa778a",
   "metadata": {},
   "source": [
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d18be-b324-45cf-8fef-10e0b917f50d",
   "metadata": {},
   "source": [
    "The accuracy of a model is closely related to the values in its confusion matrix, as accuracy is derived from the counts of correct and incorrect predictions represented in the confusion matrix.\n",
    "\n",
    "Accuracy is calculated as the ratio of the correctly classified instances (true positives and true negatives) to the total number of instances:\n",
    "\n",
    "\n",
    "Accuracy= \n",
    "TP+TN/TP+TN+FP+FN\n",
    "\n",
    "True Positive (TP): The cases in which the model correctly predicted the positive class.\n",
    "\n",
    "True Negative (TN): The cases in which the model correctly predicted the negative class.\n",
    "\n",
    "False Positive (FP): The cases in which the model incorrectly predicted the positive class (Type I error).\n",
    "\n",
    "False Negative (FN): The cases in which the model incorrectly predicted the negative class (Type II error).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948abb41-e797-4d10-8dba-79e1fa8e1c2a",
   "metadata": {},
   "source": [
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20575b4c-74c8-4215-bcd2-de1c1d0f6faf",
   "metadata": {},
   "source": [
    "A confusion matrix can be a valuable tool for identifying potential biases or limitations in your machine learning model. Here's how you can use it for that purpose:\n",
    "\n",
    "Class Imbalance: Check if there is a significant difference in the number of instances between different classes. If one class dominates the dataset, the model may become biased towards that class, leading to poor performance on minority classes.\n",
    "\n",
    "Misclassification Patterns: Examine the off-diagonal elements of the confusion matrix to identify which classes are frequently misclassified. This can highlight classes that the model struggles to distinguish, indicating potential limitations in the features or training process.\n",
    "\n",
    "False Positives vs. False Negatives: Consider the consequences of false positives and false negatives in your specific application. If one type of error is more problematic than the other, you may need to adjust the model's threshold or prioritize certain performance metrics (e.g., precision vs. recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a1ba79-bc22-4b1e-a710-a1a5502417e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
